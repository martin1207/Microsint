{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ultralytics\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from ultralytics import YOLO  \n",
    "import val\n",
    "from val import yolo2coco, coco_eval\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your classes here (same order as during YOLO training)\n",
    "classes = [\"pedestrians\", \"bikes\", \"bicyclists\", \"e-scooters\", \"e-scooterists\"]\n",
    "\n",
    "name_model=\"yolo11x\"\n",
    "# Load YOLO model\n",
    "model = YOLO(\"algos/\"+name_model+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes file created at: yolo/datasets_Test-360/one/classes.txt\n",
      "\n",
      "0: 640x1280 10 persons, 882.3ms\n",
      "Speed: 15.7ms preprocess, 882.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 787.7ms\n",
      "Speed: 3.3ms preprocess, 787.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 783.7ms\n",
      "Speed: 3.5ms preprocess, 783.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 761.4ms\n",
      "Speed: 3.3ms preprocess, 761.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 769.6ms\n",
      "Speed: 3.1ms preprocess, 769.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 770.0ms\n",
      "Speed: 3.4ms preprocess, 770.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 779.8ms\n",
      "Speed: 3.7ms preprocess, 779.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 731.2ms\n",
      "Speed: 3.1ms preprocess, 731.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 729.3ms\n",
      "Speed: 3.1ms preprocess, 729.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 700.8ms\n",
      "Speed: 3.4ms preprocess, 700.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 743.0ms\n",
      "Speed: 3.1ms preprocess, 743.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 728.5ms\n",
      "Speed: 3.2ms preprocess, 728.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 742.0ms\n",
      "Speed: 3.2ms preprocess, 742.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 731.6ms\n",
      "Speed: 3.1ms preprocess, 731.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 733.3ms\n",
      "Speed: 3.3ms preprocess, 733.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 719.5ms\n",
      "Speed: 3.5ms preprocess, 719.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 742.1ms\n",
      "Speed: 3.1ms preprocess, 742.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 730.5ms\n",
      "Speed: 3.1ms preprocess, 730.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 740.4ms\n",
      "Speed: 3.3ms preprocess, 740.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 733.4ms\n",
      "Speed: 3.1ms preprocess, 733.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 799.6ms\n",
      "Speed: 3.2ms preprocess, 799.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 750.2ms\n",
      "Speed: 3.9ms preprocess, 750.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 773.6ms\n",
      "Speed: 3.5ms preprocess, 773.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 734.1ms\n",
      "Speed: 3.1ms preprocess, 734.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 740.5ms\n",
      "Speed: 3.6ms preprocess, 740.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 750.0ms\n",
      "Speed: 3.1ms preprocess, 750.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 746.0ms\n",
      "Speed: 3.1ms preprocess, 746.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 736.0ms\n",
      "Speed: 3.1ms preprocess, 736.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 12 persons, 731.0ms\n",
      "Speed: 3.3ms preprocess, 731.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 13 persons, 760.5ms\n",
      "Speed: 3.5ms preprocess, 760.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 742.4ms\n",
      "Speed: 3.1ms preprocess, 742.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 12 persons, 754.2ms\n",
      "Speed: 3.1ms preprocess, 754.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 762.3ms\n",
      "Speed: 4.0ms preprocess, 762.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 761.7ms\n",
      "Speed: 3.1ms preprocess, 761.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 742.6ms\n",
      "Speed: 3.2ms preprocess, 742.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 728.5ms\n",
      "Speed: 3.1ms preprocess, 728.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 769.7ms\n",
      "Speed: 3.1ms preprocess, 769.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 737.8ms\n",
      "Speed: 3.1ms preprocess, 737.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 731.4ms\n",
      "Speed: 3.1ms preprocess, 731.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 744.1ms\n",
      "Speed: 3.0ms preprocess, 744.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 755.9ms\n",
      "Speed: 3.2ms preprocess, 755.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 733.6ms\n",
      "Speed: 3.5ms preprocess, 733.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 715.8ms\n",
      "Speed: 3.2ms preprocess, 715.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 824.5ms\n",
      "Speed: 3.1ms preprocess, 824.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 749.9ms\n",
      "Speed: 3.1ms preprocess, 749.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 781.0ms\n",
      "Speed: 3.1ms preprocess, 781.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 752.6ms\n",
      "Speed: 3.1ms preprocess, 752.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 732.3ms\n",
      "Speed: 3.2ms preprocess, 732.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 706.7ms\n",
      "Speed: 3.7ms preprocess, 706.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 702.5ms\n",
      "Speed: 3.2ms preprocess, 702.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 707.6ms\n",
      "Speed: 3.1ms preprocess, 707.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 709.8ms\n",
      "Speed: 3.3ms preprocess, 709.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 710.9ms\n",
      "Speed: 3.1ms preprocess, 710.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 734.5ms\n",
      "Speed: 3.1ms preprocess, 734.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 753.8ms\n",
      "Speed: 3.3ms preprocess, 753.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 741.1ms\n",
      "Speed: 3.4ms preprocess, 741.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 711.1ms\n",
      "Speed: 3.1ms preprocess, 711.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 706.3ms\n",
      "Speed: 3.6ms preprocess, 706.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 707.4ms\n",
      "Speed: 3.1ms preprocess, 707.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 702.4ms\n",
      "Speed: 3.1ms preprocess, 702.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 736.2ms\n",
      "Speed: 3.1ms preprocess, 736.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 714.7ms\n",
      "Speed: 3.3ms preprocess, 714.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 705.5ms\n",
      "Speed: 3.1ms preprocess, 705.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 703.3ms\n",
      "Speed: 3.0ms preprocess, 703.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 705.5ms\n",
      "Speed: 3.1ms preprocess, 705.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 753.5ms\n",
      "Speed: 3.1ms preprocess, 753.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 758.5ms\n",
      "Speed: 3.1ms preprocess, 758.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 752.0ms\n",
      "Speed: 3.1ms preprocess, 752.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 750.6ms\n",
      "Speed: 3.2ms preprocess, 750.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 740.3ms\n",
      "Speed: 3.3ms preprocess, 740.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 765.9ms\n",
      "Speed: 3.2ms preprocess, 765.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 770.5ms\n",
      "Speed: 3.1ms preprocess, 770.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 741.7ms\n",
      "Speed: 3.3ms preprocess, 741.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 1 bicycle, 749.3ms\n",
      "Speed: 3.3ms preprocess, 749.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 749.8ms\n",
      "Speed: 3.1ms preprocess, 749.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 741.5ms\n",
      "Speed: 3.3ms preprocess, 741.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 1 bicycle, 764.1ms\n",
      "Speed: 3.6ms preprocess, 764.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 789.6ms\n",
      "Speed: 3.3ms preprocess, 789.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 753.0ms\n",
      "Speed: 3.2ms preprocess, 753.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 739.7ms\n",
      "Speed: 3.9ms preprocess, 739.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 732.6ms\n",
      "Speed: 3.5ms preprocess, 732.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 777.4ms\n",
      "Speed: 3.2ms preprocess, 777.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 749.6ms\n",
      "Speed: 3.5ms preprocess, 749.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 1 bicycle, 741.7ms\n",
      "Speed: 3.1ms preprocess, 741.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 705.3ms\n",
      "Speed: 3.1ms preprocess, 705.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 705.3ms\n",
      "Speed: 3.3ms preprocess, 705.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 700.7ms\n",
      "Speed: 3.1ms preprocess, 700.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 716.8ms\n",
      "Speed: 3.1ms preprocess, 716.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 1 bicycle, 696.6ms\n",
      "Speed: 3.4ms preprocess, 696.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 1 bicycle, 697.4ms\n",
      "Speed: 3.1ms preprocess, 697.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 1 bicycle, 703.0ms\n",
      "Speed: 3.1ms preprocess, 703.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 765.0ms\n",
      "Speed: 3.1ms preprocess, 765.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 698.7ms\n",
      "Speed: 3.2ms preprocess, 698.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 694.7ms\n",
      "Speed: 3.1ms preprocess, 694.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 701.4ms\n",
      "Speed: 3.6ms preprocess, 701.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 3 persons, 696.1ms\n",
      "Speed: 3.1ms preprocess, 696.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 3 persons, 696.5ms\n",
      "Speed: 3.1ms preprocess, 696.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 3 persons, 700.8ms\n",
      "Speed: 3.1ms preprocess, 700.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 3 persons, 728.2ms\n",
      "Speed: 3.1ms preprocess, 728.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 3 persons, 768.7ms\n",
      "Speed: 3.1ms preprocess, 768.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 3 persons, 751.4ms\n",
      "Speed: 3.1ms preprocess, 751.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 744.9ms\n",
      "Speed: 3.1ms preprocess, 744.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 3 persons, 739.7ms\n",
      "Speed: 3.1ms preprocess, 739.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 775.4ms\n",
      "Speed: 3.1ms preprocess, 775.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 744.6ms\n",
      "Speed: 3.1ms preprocess, 744.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 741.7ms\n",
      "Speed: 3.1ms preprocess, 741.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 758.3ms\n",
      "Speed: 3.1ms preprocess, 758.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 697.7ms\n",
      "Speed: 3.2ms preprocess, 697.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 702.8ms\n",
      "Speed: 3.0ms preprocess, 702.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 696.4ms\n",
      "Speed: 3.1ms preprocess, 696.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 697.9ms\n",
      "Speed: 3.1ms preprocess, 697.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 693.8ms\n",
      "Speed: 3.1ms preprocess, 693.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 696.3ms\n",
      "Speed: 3.4ms preprocess, 696.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 701.9ms\n",
      "Speed: 3.1ms preprocess, 701.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 693.5ms\n",
      "Speed: 3.1ms preprocess, 693.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 696.1ms\n",
      "Speed: 3.1ms preprocess, 696.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 700.6ms\n",
      "Speed: 3.1ms preprocess, 700.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 695.6ms\n",
      "Speed: 3.2ms preprocess, 695.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 696.2ms\n",
      "Speed: 3.1ms preprocess, 696.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 733.3ms\n",
      "Speed: 3.1ms preprocess, 733.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 723.8ms\n",
      "Speed: 3.1ms preprocess, 723.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 703.8ms\n",
      "Speed: 3.1ms preprocess, 703.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 760.6ms\n",
      "Speed: 3.3ms preprocess, 760.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 736.1ms\n",
      "Speed: 3.4ms preprocess, 736.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 741.8ms\n",
      "Speed: 3.1ms preprocess, 741.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 721.1ms\n",
      "Speed: 3.1ms preprocess, 721.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 697.7ms\n",
      "Speed: 3.3ms preprocess, 697.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 703.3ms\n",
      "Speed: 3.1ms preprocess, 703.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 698.9ms\n",
      "Speed: 3.1ms preprocess, 698.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 701.6ms\n",
      "Speed: 3.1ms preprocess, 701.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 702.1ms\n",
      "Speed: 3.1ms preprocess, 702.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 701.5ms\n",
      "Speed: 3.3ms preprocess, 701.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 704.5ms\n",
      "Speed: 3.2ms preprocess, 704.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 705.1ms\n",
      "Speed: 3.1ms preprocess, 705.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 702.3ms\n",
      "Speed: 3.1ms preprocess, 702.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 703.9ms\n",
      "Speed: 3.3ms preprocess, 703.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 702.8ms\n",
      "Speed: 3.1ms preprocess, 702.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 702.5ms\n",
      "Speed: 3.1ms preprocess, 702.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 702.3ms\n",
      "Speed: 3.1ms preprocess, 702.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 705.0ms\n",
      "Speed: 3.2ms preprocess, 705.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 719.3ms\n",
      "Speed: 3.5ms preprocess, 719.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 710.2ms\n",
      "Speed: 3.2ms preprocess, 710.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 709.5ms\n",
      "Speed: 3.1ms preprocess, 709.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 707.8ms\n",
      "Speed: 3.0ms preprocess, 707.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 730.6ms\n",
      "Speed: 3.0ms preprocess, 730.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 704.0ms\n",
      "Speed: 3.6ms preprocess, 704.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 736.8ms\n",
      "Speed: 3.2ms preprocess, 736.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 764.4ms\n",
      "Speed: 3.1ms preprocess, 764.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 730.3ms\n",
      "Speed: 3.1ms preprocess, 730.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 702.4ms\n",
      "Speed: 3.1ms preprocess, 702.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 704.3ms\n",
      "Speed: 3.3ms preprocess, 704.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 700.4ms\n",
      "Speed: 3.1ms preprocess, 700.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 3 persons, 741.6ms\n",
      "Speed: 3.2ms preprocess, 741.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 732.5ms\n",
      "Speed: 3.1ms preprocess, 732.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 749.5ms\n",
      "Speed: 3.2ms preprocess, 749.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 711.1ms\n",
      "Speed: 3.2ms preprocess, 711.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 711.1ms\n",
      "Speed: 3.0ms preprocess, 711.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 706.1ms\n",
      "Speed: 3.1ms preprocess, 706.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 703.6ms\n",
      "Speed: 3.2ms preprocess, 703.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 739.7ms\n",
      "Speed: 3.1ms preprocess, 739.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 733.8ms\n",
      "Speed: 3.1ms preprocess, 733.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 771.1ms\n",
      "Speed: 3.1ms preprocess, 771.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 758.7ms\n",
      "Speed: 3.3ms preprocess, 758.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 715.5ms\n",
      "Speed: 3.2ms preprocess, 715.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 708.8ms\n",
      "Speed: 3.1ms preprocess, 708.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 707.4ms\n",
      "Speed: 3.1ms preprocess, 707.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 704.6ms\n",
      "Speed: 3.2ms preprocess, 704.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 707.8ms\n",
      "Speed: 3.1ms preprocess, 707.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 704.3ms\n",
      "Speed: 3.0ms preprocess, 704.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 700.8ms\n",
      "Speed: 3.1ms preprocess, 700.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 709.7ms\n",
      "Speed: 3.1ms preprocess, 709.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 715.3ms\n",
      "Speed: 3.1ms preprocess, 715.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 704.5ms\n",
      "Speed: 3.1ms preprocess, 704.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 703.6ms\n",
      "Speed: 3.1ms preprocess, 703.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 707.0ms\n",
      "Speed: 3.1ms preprocess, 707.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 700.0ms\n",
      "Speed: 3.2ms preprocess, 700.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 706.4ms\n",
      "Speed: 3.6ms preprocess, 706.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 706.1ms\n",
      "Speed: 3.2ms preprocess, 706.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 3 persons, 708.2ms\n",
      "Speed: 3.1ms preprocess, 708.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 710.9ms\n",
      "Speed: 3.5ms preprocess, 710.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 704.5ms\n",
      "Speed: 3.2ms preprocess, 704.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 710.0ms\n",
      "Speed: 3.1ms preprocess, 710.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 699.7ms\n",
      "Speed: 3.1ms preprocess, 699.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 1 bicycle, 705.5ms\n",
      "Speed: 3.5ms preprocess, 705.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 700.3ms\n",
      "Speed: 3.2ms preprocess, 700.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 701.8ms\n",
      "Speed: 3.3ms preprocess, 701.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 699.3ms\n",
      "Speed: 3.1ms preprocess, 699.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 709.8ms\n",
      "Speed: 3.3ms preprocess, 709.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 709.4ms\n",
      "Speed: 3.1ms preprocess, 709.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 700.3ms\n",
      "Speed: 3.1ms preprocess, 700.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 710.7ms\n",
      "Speed: 3.1ms preprocess, 710.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 713.6ms\n",
      "Speed: 3.1ms preprocess, 713.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 743.6ms\n",
      "Speed: 3.4ms preprocess, 743.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 760.8ms\n",
      "Speed: 3.1ms preprocess, 760.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 803.3ms\n",
      "Speed: 3.4ms preprocess, 803.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 747.5ms\n",
      "Speed: 3.2ms preprocess, 747.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 728.0ms\n",
      "Speed: 3.0ms preprocess, 728.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 736.8ms\n",
      "Speed: 3.1ms preprocess, 736.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 758.5ms\n",
      "Speed: 3.6ms preprocess, 758.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 720.3ms\n",
      "Speed: 3.1ms preprocess, 720.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 715.9ms\n",
      "Speed: 3.0ms preprocess, 715.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 1 bicycle, 713.3ms\n",
      "Speed: 3.2ms preprocess, 713.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 1 bicycle, 717.6ms\n",
      "Speed: 3.1ms preprocess, 717.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 1 bicycle, 712.1ms\n",
      "Speed: 3.2ms preprocess, 712.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 1 bicycle, 710.8ms\n",
      "Speed: 3.2ms preprocess, 710.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 884.5ms\n",
      "Speed: 3.1ms preprocess, 884.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 700.5ms\n",
      "Speed: 3.1ms preprocess, 700.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 702.7ms\n",
      "Speed: 3.1ms preprocess, 702.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 703.9ms\n",
      "Speed: 3.1ms preprocess, 703.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 726.0ms\n",
      "Speed: 3.3ms preprocess, 726.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 701.3ms\n",
      "Speed: 3.1ms preprocess, 701.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 12 persons, 705.8ms\n",
      "Speed: 3.1ms preprocess, 705.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 705.8ms\n",
      "Speed: 3.1ms preprocess, 705.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 726.4ms\n",
      "Speed: 4.2ms preprocess, 726.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 717.6ms\n",
      "Speed: 3.1ms preprocess, 717.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 704.6ms\n",
      "Speed: 3.1ms preprocess, 704.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 710.1ms\n",
      "Speed: 3.2ms preprocess, 710.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 12 persons, 710.1ms\n",
      "Speed: 3.1ms preprocess, 710.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 763.9ms\n",
      "Speed: 3.2ms preprocess, 763.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 726.0ms\n",
      "Speed: 3.2ms preprocess, 726.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 702.2ms\n",
      "Speed: 3.1ms preprocess, 702.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 703.6ms\n",
      "Speed: 3.1ms preprocess, 703.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 710.3ms\n",
      "Speed: 3.0ms preprocess, 710.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 711.0ms\n",
      "Speed: 3.1ms preprocess, 711.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 711.3ms\n",
      "Speed: 3.4ms preprocess, 711.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 707.0ms\n",
      "Speed: 3.6ms preprocess, 707.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 741.4ms\n",
      "Speed: 3.5ms preprocess, 741.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 730.8ms\n",
      "Speed: 3.1ms preprocess, 730.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 735.3ms\n",
      "Speed: 3.1ms preprocess, 735.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 746.6ms\n",
      "Speed: 3.3ms preprocess, 746.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 756.6ms\n",
      "Speed: 3.2ms preprocess, 756.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 739.6ms\n",
      "Speed: 3.2ms preprocess, 739.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 710.5ms\n",
      "Speed: 3.1ms preprocess, 710.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 703.9ms\n",
      "Speed: 3.6ms preprocess, 703.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 711.2ms\n",
      "Speed: 3.3ms preprocess, 711.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 724.7ms\n",
      "Speed: 3.1ms preprocess, 724.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 702.6ms\n",
      "Speed: 3.1ms preprocess, 702.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 701.7ms\n",
      "Speed: 3.1ms preprocess, 701.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 700.9ms\n",
      "Speed: 3.1ms preprocess, 700.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 697.0ms\n",
      "Speed: 3.1ms preprocess, 697.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 760.4ms\n",
      "Speed: 6.5ms preprocess, 760.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 705.7ms\n",
      "Speed: 3.1ms preprocess, 705.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 701.6ms\n",
      "Speed: 3.1ms preprocess, 701.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 692.8ms\n",
      "Speed: 3.2ms preprocess, 692.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 692.3ms\n",
      "Speed: 3.1ms preprocess, 692.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 692.0ms\n",
      "Speed: 3.0ms preprocess, 692.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 701.3ms\n",
      "Speed: 3.0ms preprocess, 701.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 705.4ms\n",
      "Speed: 3.3ms preprocess, 705.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 706.8ms\n",
      "Speed: 3.1ms preprocess, 706.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 701.3ms\n",
      "Speed: 3.6ms preprocess, 701.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 711.0ms\n",
      "Speed: 3.1ms preprocess, 711.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 704.1ms\n",
      "Speed: 3.5ms preprocess, 704.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 701.9ms\n",
      "Speed: 3.1ms preprocess, 701.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 702.6ms\n",
      "Speed: 3.1ms preprocess, 702.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 725.0ms\n",
      "Speed: 3.1ms preprocess, 725.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 741.1ms\n",
      "Speed: 3.1ms preprocess, 741.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 737.2ms\n",
      "Speed: 3.1ms preprocess, 737.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 735.9ms\n",
      "Speed: 3.2ms preprocess, 735.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 738.4ms\n",
      "Speed: 3.1ms preprocess, 738.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 728.1ms\n",
      "Speed: 3.1ms preprocess, 728.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 1 bicycle, 868.1ms\n",
      "Speed: 3.1ms preprocess, 868.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 781.3ms\n",
      "Speed: 3.1ms preprocess, 781.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 1 bicycle, 1183.7ms\n",
      "Speed: 3.1ms preprocess, 1183.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 736.7ms\n",
      "Speed: 3.1ms preprocess, 736.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 711.9ms\n",
      "Speed: 3.2ms preprocess, 711.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 699.0ms\n",
      "Speed: 3.1ms preprocess, 699.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 708.4ms\n",
      "Speed: 3.0ms preprocess, 708.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 696.4ms\n",
      "Speed: 3.2ms preprocess, 696.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 705.5ms\n",
      "Speed: 3.5ms preprocess, 705.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 753.5ms\n",
      "Speed: 3.5ms preprocess, 753.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 741.5ms\n",
      "Speed: 3.1ms preprocess, 741.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 754.1ms\n",
      "Speed: 3.4ms preprocess, 754.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 762.7ms\n",
      "Speed: 3.1ms preprocess, 762.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 779.6ms\n",
      "Speed: 3.4ms preprocess, 779.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 755.7ms\n",
      "Speed: 3.4ms preprocess, 755.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 750.5ms\n",
      "Speed: 3.1ms preprocess, 750.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 748.2ms\n",
      "Speed: 3.1ms preprocess, 748.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 742.9ms\n",
      "Speed: 3.1ms preprocess, 742.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 740.9ms\n",
      "Speed: 3.2ms preprocess, 740.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 736.4ms\n",
      "Speed: 3.1ms preprocess, 736.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 703.8ms\n",
      "Speed: 3.3ms preprocess, 703.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 725.4ms\n",
      "Speed: 3.2ms preprocess, 725.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 700.7ms\n",
      "Speed: 3.0ms preprocess, 700.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 720.9ms\n",
      "Speed: 3.1ms preprocess, 720.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 719.2ms\n",
      "Speed: 3.4ms preprocess, 719.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 778.8ms\n",
      "Speed: 3.1ms preprocess, 778.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 788.9ms\n",
      "Speed: 3.2ms preprocess, 788.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 706.1ms\n",
      "Speed: 3.2ms preprocess, 706.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 701.1ms\n",
      "Speed: 3.2ms preprocess, 701.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 705.0ms\n",
      "Speed: 3.2ms preprocess, 705.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 699.6ms\n",
      "Speed: 3.3ms preprocess, 699.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 702.9ms\n",
      "Speed: 3.6ms preprocess, 702.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 709.5ms\n",
      "Speed: 3.1ms preprocess, 709.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 713.6ms\n",
      "Speed: 3.3ms preprocess, 713.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 703.6ms\n",
      "Speed: 3.6ms preprocess, 703.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 696.2ms\n",
      "Speed: 3.1ms preprocess, 696.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 698.8ms\n",
      "Speed: 3.1ms preprocess, 698.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 697.9ms\n",
      "Speed: 3.1ms preprocess, 697.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 715.8ms\n",
      "Speed: 3.1ms preprocess, 715.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 705.3ms\n",
      "Speed: 3.5ms preprocess, 705.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 699.4ms\n",
      "Speed: 3.1ms preprocess, 699.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 707.9ms\n",
      "Speed: 3.7ms preprocess, 707.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 700.9ms\n",
      "Speed: 3.2ms preprocess, 700.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 742.3ms\n",
      "Speed: 3.1ms preprocess, 742.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 762.7ms\n",
      "Speed: 3.1ms preprocess, 762.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 753.6ms\n",
      "Speed: 3.0ms preprocess, 753.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 807.6ms\n",
      "Speed: 3.6ms preprocess, 807.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 731.6ms\n",
      "Speed: 3.6ms preprocess, 731.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 735.3ms\n",
      "Speed: 3.1ms preprocess, 735.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 735.2ms\n",
      "Speed: 3.1ms preprocess, 735.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 3 persons, 745.3ms\n",
      "Speed: 3.1ms preprocess, 745.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 737.9ms\n",
      "Speed: 3.3ms preprocess, 737.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 753.4ms\n",
      "Speed: 4.0ms preprocess, 753.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 737.7ms\n",
      "Speed: 3.1ms preprocess, 737.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 845.1ms\n",
      "Speed: 3.1ms preprocess, 845.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 797.2ms\n",
      "Speed: 3.3ms preprocess, 797.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 744.5ms\n",
      "Speed: 3.2ms preprocess, 744.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 752.9ms\n",
      "Speed: 3.1ms preprocess, 752.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 752.7ms\n",
      "Speed: 3.2ms preprocess, 752.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 718.1ms\n",
      "Speed: 3.1ms preprocess, 718.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 715.3ms\n",
      "Speed: 3.1ms preprocess, 715.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 3 persons, 712.2ms\n",
      "Speed: 3.2ms preprocess, 712.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 713.4ms\n",
      "Speed: 3.3ms preprocess, 713.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 716.1ms\n",
      "Speed: 3.1ms preprocess, 716.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 715.8ms\n",
      "Speed: 3.4ms preprocess, 715.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 717.4ms\n",
      "Speed: 3.2ms preprocess, 717.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 722.8ms\n",
      "Speed: 3.1ms preprocess, 722.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 715.0ms\n",
      "Speed: 3.2ms preprocess, 715.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 714.6ms\n",
      "Speed: 3.1ms preprocess, 714.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 712.8ms\n",
      "Speed: 3.3ms preprocess, 712.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 712.6ms\n",
      "Speed: 3.2ms preprocess, 712.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 713.1ms\n",
      "Speed: 3.1ms preprocess, 713.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 713.8ms\n",
      "Speed: 3.1ms preprocess, 713.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 718.6ms\n",
      "Speed: 3.1ms preprocess, 718.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 709.9ms\n",
      "Speed: 3.1ms preprocess, 709.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 717.9ms\n",
      "Speed: 3.2ms preprocess, 717.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 711.1ms\n",
      "Speed: 3.1ms preprocess, 711.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 4 persons, 700.8ms\n",
      "Speed: 3.5ms preprocess, 700.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 714.7ms\n",
      "Speed: 3.1ms preprocess, 714.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 5 persons, 709.3ms\n",
      "Speed: 3.3ms preprocess, 709.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 709.1ms\n",
      "Speed: 3.1ms preprocess, 709.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 708.0ms\n",
      "Speed: 3.1ms preprocess, 708.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 710.1ms\n",
      "Speed: 3.1ms preprocess, 710.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 704.1ms\n",
      "Speed: 3.1ms preprocess, 704.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 704.6ms\n",
      "Speed: 3.2ms preprocess, 704.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 710.4ms\n",
      "Speed: 3.0ms preprocess, 710.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 713.0ms\n",
      "Speed: 3.0ms preprocess, 713.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 707.1ms\n",
      "Speed: 3.1ms preprocess, 707.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 706.6ms\n",
      "Speed: 3.2ms preprocess, 706.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 711.6ms\n",
      "Speed: 3.0ms preprocess, 711.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 710.2ms\n",
      "Speed: 3.0ms preprocess, 710.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 712.9ms\n",
      "Speed: 3.1ms preprocess, 712.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 707.7ms\n",
      "Speed: 3.2ms preprocess, 707.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 749.2ms\n",
      "Speed: 3.1ms preprocess, 749.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 743.6ms\n",
      "Speed: 3.1ms preprocess, 743.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 6 persons, 749.6ms\n",
      "Speed: 3.1ms preprocess, 749.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 762.2ms\n",
      "Speed: 3.1ms preprocess, 762.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 737.6ms\n",
      "Speed: 3.1ms preprocess, 737.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 740.2ms\n",
      "Speed: 3.1ms preprocess, 740.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 1049.9ms\n",
      "Speed: 3.4ms preprocess, 1049.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 1342.0ms\n",
      "Speed: 33.3ms preprocess, 1342.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 740.7ms\n",
      "Speed: 3.1ms preprocess, 740.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 733.6ms\n",
      "Speed: 3.1ms preprocess, 733.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 706.9ms\n",
      "Speed: 3.1ms preprocess, 706.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 704.7ms\n",
      "Speed: 3.1ms preprocess, 704.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 692.0ms\n",
      "Speed: 3.1ms preprocess, 692.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 699.4ms\n",
      "Speed: 3.0ms preprocess, 699.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 703.8ms\n",
      "Speed: 3.4ms preprocess, 703.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 705.3ms\n",
      "Speed: 3.1ms preprocess, 705.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 701.5ms\n",
      "Speed: 3.1ms preprocess, 701.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 708.5ms\n",
      "Speed: 3.1ms preprocess, 708.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 702.8ms\n",
      "Speed: 3.1ms preprocess, 702.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 704.5ms\n",
      "Speed: 3.1ms preprocess, 704.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 714.6ms\n",
      "Speed: 3.1ms preprocess, 714.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 711.3ms\n",
      "Speed: 3.2ms preprocess, 711.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 708.5ms\n",
      "Speed: 3.1ms preprocess, 708.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 704.1ms\n",
      "Speed: 3.1ms preprocess, 704.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 701.0ms\n",
      "Speed: 3.1ms preprocess, 701.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 708.1ms\n",
      "Speed: 3.0ms preprocess, 708.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 699.7ms\n",
      "Speed: 3.5ms preprocess, 699.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 705.7ms\n",
      "Speed: 3.1ms preprocess, 705.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 707.9ms\n",
      "Speed: 3.1ms preprocess, 707.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 12 persons, 700.6ms\n",
      "Speed: 3.1ms preprocess, 700.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 741.8ms\n",
      "Speed: 3.1ms preprocess, 741.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 765.7ms\n",
      "Speed: 3.1ms preprocess, 765.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 728.1ms\n",
      "Speed: 3.1ms preprocess, 728.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 751.5ms\n",
      "Speed: 3.2ms preprocess, 751.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 738.0ms\n",
      "Speed: 3.1ms preprocess, 738.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 752.4ms\n",
      "Speed: 3.3ms preprocess, 752.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 752.2ms\n",
      "Speed: 3.2ms preprocess, 752.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 764.9ms\n",
      "Speed: 3.6ms preprocess, 764.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 755.2ms\n",
      "Speed: 3.0ms preprocess, 755.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 757.0ms\n",
      "Speed: 3.0ms preprocess, 757.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 11 persons, 747.4ms\n",
      "Speed: 3.3ms preprocess, 747.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 748.6ms\n",
      "Speed: 3.1ms preprocess, 748.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 746.0ms\n",
      "Speed: 3.5ms preprocess, 746.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 10 persons, 756.6ms\n",
      "Speed: 3.1ms preprocess, 756.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 7 persons, 757.8ms\n",
      "Speed: 3.1ms preprocess, 757.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 740.7ms\n",
      "Speed: 3.1ms preprocess, 740.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 8 persons, 741.2ms\n",
      "Speed: 3.1ms preprocess, 741.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 739.9ms\n",
      "Speed: 3.2ms preprocess, 739.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 759.9ms\n",
      "Speed: 3.1ms preprocess, 759.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n",
      "\n",
      "0: 640x1280 9 persons, 737.6ms\n",
      "Speed: 3.1ms preprocess, 737.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 1280)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define your classes here (same order as during YOLO training)\n",
    "classes = [\"pedestrians\", \"bikes\", \"bicyclists\", \"e-scooters\", \"e-scooterists\"]\n",
    "\n",
    "name_model=\"MicroVision-Chalmers-x-20250304\"\n",
    "# Load YOLO model\n",
    "model = YOLO(\"algos/\"+name_model+\".pt\")\n",
    "#model=YOLO('runs/detect/train11/weights/best.pt')\n",
    "video_name='Test-360'\n",
    "# Open the video file\n",
    "video_path = \"Videos/\" + video_name + \".mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video frame dimensions and fps\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "images_dir = \"yolo/datasets_\"+ video_name +\"/one/images\"\n",
    "labels_dir = \"yolo/datasets_\"+ video_name +\"/one/labels\"\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "# Create the classes.txt file\n",
    "classes_file = \"yolo/datasets_\"+ video_name +\"/one/classes.txt\"\n",
    "with open(classes_file, \"w\") as class_f:\n",
    "    for cls in classes:\n",
    "        class_f.write(f\"{cls}\\n\")\n",
    "\n",
    "print(f\"Classes file created at: {classes_file}\")\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "output_path = \"predictions/annotated_video_\"+ video_name + '_'+name_model +\".mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "frame_idx = 0  # Frame counter\n",
    "\n",
    "# Process video frames\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Run YOLO detection\n",
    "    results = model.track(frame, persist=True, imgsz=1280, conf=0.3, classes=[0, 1])\n",
    "\n",
    "    # Visualize results on the frame\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Save the current frame as an image for Label Studio\n",
    "    image_file = os.path.join(images_dir, f\"frame_{frame_idx:04d}.jpg\")\n",
    "    cv2.imwrite(image_file, frame)\n",
    "\n",
    "    # Save detections in YOLO format\n",
    "    label_file = os.path.join(labels_dir, f\"frame_{frame_idx:04d}.txt\")\n",
    "    with open(label_file, \"w\") as f:\n",
    "        for r in results[0].boxes:\n",
    "            cls = int(r.cls)\n",
    "            x_center, y_center, w, h = r.xywhn[0]  # normalized (x_center, y_center, width, height)\n",
    "\n",
    "            # Write to YOLO label file\n",
    "            f.write(f\"{cls} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "          \n",
    "      \n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    # Display the annotated frame (optional, can comment out)\n",
    "    # cv2.imshow(\"Annotated Frame\", annotated_frame)\n",
    "\n",
    "    # Break loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    frame_idx += 1  # Increment frame counter\n",
    "\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier dataset.yaml créé avec succès !\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Définition du dataset\n",
    "dataset = {\n",
    "    \"train\": \"/Users/martin.dejaeghere/Microsint2/yolo/datasets_tolabel_copie/one/train\",\n",
    "    \"val\": \"/Users/martin.dejaeghere/Microsint2/yolo/datasets_tolabel_copie/one/val\",\n",
    "    \"nc\": 5,  # Nombre de classes\n",
    "    \"names\": ['pedestrians', 'bikes', 'bicyclists', 'e-scooterists', 'e-scooters'] # Classes\n",
    "}\n",
    "\n",
    "# Sauvegarde dans un fichier\n",
    "with open(\"dataset.yaml\", \"w\") as file:\n",
    "    yaml.dump(dataset, file, default_flow_style=False)\n",
    "\n",
    "print(\"Fichier dataset.yaml créé avec succès !\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_model=\"MicroVision-Chalmers-x-20250304\"\n",
    "# Load YOLO model\n",
    "model = YOLO(\"algos/\"+name_model+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.94 🚀 Python-3.11.11 torch-2.6.0 CPU (Apple M3 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=algos/MicroVision-Chalmers-x-20250304.pt, data=dataset.yaml, epochs=5, time=None, patience=100, batch=5, imgsz=1280, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train11\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n",
      " 10                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2   1700352  ultralytics.nn.modules.block.C3k2            [1536, 384, 2, True]          \n",
      " 17                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   5317632  ultralytics.nn.modules.block.C3k2            [1152, 768, 2, True]          \n",
      " 20                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 23        [16, 19, 22]  1   3151327  ultralytics.nn.modules.head.Detect           [5, [384, 768, 768]]          \n",
      "YOLO11x summary: 357 layers, 56,879,551 parameters, 56,879,535 gradients, 195.5 GFLOPs\n",
      "\n",
      "Transferred 1015/1015 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train11', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/martin.dejaeghere/Microsint2/yolo/datasets_tolabel_copie/one/train/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/martin.dejaeghere/Microsint2/yolo/datasets_tolabel_copie/one/val/labels.cache... 12 images, 0 backgrounds, 0 corrupt: 100%|██████████| 12/12 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train11/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005078125), 173 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train11\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         0G      1.118      0.953      1.074         90       1280: 100%|██████████| 7/7 [09:16<00:00, 79.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<00:00,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         12        139      0.898      0.765      0.858      0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5         0G      1.032      0.667      1.016        114       1280: 100%|██████████| 7/7 [08:42<00:00, 74.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<00:00,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         12        139      0.833       0.81      0.853      0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         0G      1.017     0.6337      1.012         84       1280: 100%|██████████| 7/7 [08:00<00:00, 68.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<00:00,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         12        139      0.821      0.822      0.853      0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5         0G      1.006     0.6236     0.9662        118       1280: 100%|██████████| 7/7 [07:18<00:00, 62.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<00:00,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         12        139      0.794      0.837      0.856      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5         0G      1.007     0.6062     0.9661        119       1280: 100%|██████████| 7/7 [07:39<00:00, 65.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<00:00,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         12        139      0.843      0.785       0.86       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.710 hours.\n",
      "Optimizer stripped from runs/detect/train11/weights/last.pt, 114.4MB\n",
      "Optimizer stripped from runs/detect/train11/weights/best.pt, 114.4MB\n",
      "\n",
      "Validating runs/detect/train11/weights/best.pt...\n",
      "Ultralytics 8.3.94 🚀 Python-3.11.11 torch-2.6.0 CPU (Apple M3 Pro)\n",
      "YOLO11x summary (fused): 190 layers, 56,832,799 parameters, 0 gradients, 194.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:13<00:00,  6.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         12        139        0.9      0.765      0.859      0.731\n",
      "           pedestrians         12         88       0.91      0.572      0.767      0.627\n",
      "                 bikes          9         25          1      0.649      0.876      0.705\n",
      "            bicyclists          8          8      0.978      0.875      0.878      0.841\n",
      "         e-scooterists          7         15          1      0.729      0.778      0.751\n",
      "            e-scooters          2          3      0.615          1      0.995      0.733\n",
      "Speed: 2.2ms preprocess, 1100.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data=\"dataset.yaml\", epochs=5, batch=5, imgsz=1280, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.87 🚀 Python-3.11.11 torch-2.6.0 CPU (Apple M3 Pro)\n",
      "YOLO11x summary (fused): 190 layers, 56,832,799 parameters, 0 gradients, 194.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/martin.dejaeghere/Microsint2/yolo/datasets_tolabel_copie/one/labels.cache... 46 images, 0 backgrounds, 0 corrupt: 100%|██████████| 46/46 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [01:54<00:00, 38.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         46        563      0.908      0.636      0.794      0.665\n",
      "                person         46        420       0.88       0.54      0.733      0.581\n",
      "               bicycle         23         67      0.927      0.567       0.76      0.629\n",
      "               cyclist         21         28      0.769      0.714      0.805       0.71\n",
      "             e-scooter         20         39      0.964      0.692      0.841      0.717\n",
      "          e-scooterist          8          9          1      0.667      0.833      0.689\n",
      "Speed: 1.3ms preprocess, 2453.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val22\u001b[0m\n",
      "0.6653092581562342\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Validate with a custom dataset\n",
    "name_model=\"MicroVision-Chalmers-x-distorted-20250318\"\n",
    "# Load YOLO model\n",
    "model = YOLO(\"algos/\"+name_model+\".pt\")\n",
    "\n",
    "metrics = model.val(data=\"dataset.yaml\",conf=0.4) \n",
    "print(metrics.box.map)  # map50-95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier dataset.yaml créé avec succès !\n",
      "Ultralytics 8.3.87 🚀 Python-3.11.11 torch-2.6.0 CPU (Apple M3 Pro)\n",
      "YOLO11x summary (fused): 190 layers, 56,919,424 parameters, 0 gradients, 194.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/martin.dejaeghere/Microsint2/yolo/datasets_tolabel_copie/one/labels.cache... 46 images, 0 backgrounds, 0 corrupt: 100%|██████████| 46/46 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [01:56<00:00, 38.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         46        487      0.699      0.568        0.6      0.465\n",
      "                person         46        420      0.772      0.614      0.657      0.492\n",
      "               bicycle         23         67      0.625      0.522      0.544      0.438\n",
      "Speed: 1.4ms preprocess, 2494.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val19\u001b[0m\n",
      "0.46490512603597517\n"
     ]
    }
   ],
   "source": [
    "# Définition du dataset\n",
    "dataset = {\n",
    "    \"train\": \"/Users/martin.dejaeghere/Microsint2/yolo/datasets_GS010646\",\n",
    "    \"val\": \"/Users/martin.dejaeghere/Microsint2/yolo/datasets_tolabel_copie\",\n",
    "    \"nc\": 2,  # Nombre de classes\n",
    "    \"names\": ['persons', 'bikes'] # Classes\n",
    "}\n",
    "\n",
    "# Sauvegarde dans un fichier\n",
    "with open(\"dataset.yaml\", \"w\") as file:\n",
    "    yaml.dump(dataset, file, default_flow_style=False)\n",
    "\n",
    "print(\"Fichier dataset.yaml créé avec succès !\")\n",
    "\n",
    "name_model=\"yolo11x\"\n",
    "model=YOLO(\"algos/\"+name_model+\".pt\")\n",
    "\n",
    "# Validate with a custom dataset\n",
    "metrics = model.val(data=\"dataset.yaml\",conf=0.4,imgsz=1280,classes=[0, 1])  \n",
    "print(metrics.box.map)  # map50-95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path='/Users/martin.dejaeghere/Microsint2/algos/MicroVision-Chalmers-x-20250304.pt'\n",
    "yaml_path='/Users/martin.dejaeghere/Microsint2/dataset.yaml'\n",
    "val_path='/Users/martin.dejaeghere/Microsint2/runs/detect/MicroVision-Chalmers-x-202503045'\n",
    "data_path='/Users/martin.dejaeghere/Microsint2/yolo/datasets_tolabel_copie/one'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n",
      "Run validation ...\n",
      "Ultralytics 8.3.94 🚀 Python-3.11.11 torch-2.6.0 CPU (Apple M3 Pro)\n",
      "YOLO11x summary (fused): 190 layers, 56,832,799 parameters, 0 gradients, 194.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/martin.dejaeghere/Microsint2/yolo/datasets_tolabel_copie/one/val/labels.cache... 12 images, 0 backgrounds, 0 corrupt: 100%|██████████| 12/12 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:13<00:00, 13.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         12        139      0.892      0.726      0.855      0.755\n",
      "                person         12         88      0.959      0.526      0.762      0.655\n",
      "               bicycle          9         25      0.953       0.52      0.838      0.697\n",
      "               cyclist          8          8          1      0.867      0.882      0.866\n",
      "             e-scooter          7         15          1      0.716      0.801      0.783\n",
      "          e-scooterist          2          3      0.548          1      0.995      0.777\n",
      "Speed: 1.7ms preprocess, 1079.4ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Saving runs/detect/MicroVision-Chalmers-x-202503045/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/MicroVision-Chalmers-x-202503045\u001b[0m\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.736\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.841\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.798\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.675\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.960\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.435\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.769\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.776\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.731\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.967\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800\n"
     ]
    }
   ],
   "source": [
    "coco_eval(model_path, yaml_path, val_path, data_path, 128, 288, split=\"val\", iou=0.45, agnostic_nms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO \n",
    "from pycocotools.cocoeval import COCOeval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "pred_json = f\"{val_path}/predictions.json\"\n",
    "\n",
    "    # Convert labels to COCO\n",
    "annotations_json = f\"{val_path}/annotations.json\"\n",
    "yolo2coco(\n",
    "        yolo_data_dir=Path(data_path, 'val'),\n",
    "        out_json=annotations_json\n",
    "    )\n",
    "        \n",
    "    # Run COCO evaluation\n",
    "anno = COCO(annotations_json)\n",
    "imgIds = sorted(anno.getImgIds())\n",
    "\n",
    "pred = anno.loadRes(pred_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"
     ]
    }
   ],
   "source": [
    "val = COCOeval(anno, pred, \"bbox\")\n",
    "val.params.imgIds = imgIds\n",
    "    \n",
    "    # Update thresholds for object sizes\n",
    "val.params.areaRng = [\n",
    "        [0 ** 2, 1e5 ** 2], \n",
    "        [0 ** 2, 188 ** 2], \n",
    "        [188 ** 2, 288 ** 2], \n",
    "        [288 ** 2, 1e5 ** 2]\n",
    "    ]\n",
    "\n",
    "val.evaluate()\n",
    "val.accumulate()\n",
    "val.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224\n",
      "548\n",
      "13\n",
      "43\n",
      "1102\n",
      "563\n",
      "23\n",
      "35\n",
      "1002\n",
      "553\n",
      "36\n",
      "74\n",
      "1645\n",
      "562\n",
      "19\n",
      "47\n",
      "1682\n",
      "555\n",
      "19\n",
      "40\n",
      "950\n",
      "546\n",
      "9\n",
      "27\n",
      "1733\n",
      "557\n",
      "10\n",
      "31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Image avec bounding boxes sauvegardée sous 'output_with_boxes.jpg'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 📌 Charger le fichier JSON\n",
    "json_file = \"/Users/martin.dejaeghere/Microsint2/runs/detect/val56/annotations.json\"\n",
    "with open(json_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 📌 Charger l'image cible\n",
    "image_name = \"frame_0961\"\n",
    "image_path = f\"/Users/martin.dejaeghere/Microsint2/yolo/datasets_tolabel_copie/one/val/images/{image_name}.jpg\"\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    raise FileNotFoundError(f\"❌ Image '{image_path}' non trouvée. Vérifie le chemin !\")\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convertir en RGB pour Matplotlib\n",
    "\n",
    "# 📌 Dessiner uniquement les bounding boxes de \"frame_0961\"\n",
    "for item in data[\"annotations\"]:\n",
    "    if item[\"image_id\"] == image_name:  # 🟢 Filtrer uniquement cette image\n",
    "        x, y, w, h = map(int, item[\"bbox\"])  # Convertir en entier\n",
    "        print(x)\n",
    "        print(y)\n",
    "        print(w)\n",
    "        print(h)\n",
    "        category_id = item[\"category_id\"]\n",
    "        score = item.get(\"score\", None)\n",
    "\n",
    "        # 📌 Couleur (annotations = bleu, prédictions = vert)\n",
    "        color = (0, 255, 0) if \"score\" in item else (255, 0, 0)\n",
    "        \n",
    "        # 📌 Dessiner le rectangle\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "        # 📌 Ajouter du texte avec `category_id` et `score`\n",
    "        label = f\"Class {category_id}\"\n",
    "        if score:\n",
    "            label += f\" ({score:.2f})\"\n",
    "        \n",
    "        cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "# 📌 Afficher l’image avec Matplotlib\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# 📌 Sauvegarder l’image avec les boxes (optionnel)\n",
    "output_path = \"output_with_boxes.jpg\"\n",
    "cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "print(f\"✅ Image avec bounding boxes sauvegardée sous '{output_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Image avec bounding boxes YOLO sauvegardée sous 'output_with_yolo_boxes.jpg'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image et dimensions (tu devras ajuster ces valeurs en fonction de ton image réelle)\n",
    "image_path = \"/Users/martin.dejaeghere/Microsint2/yolo/datasets_tolabel_copie/one/val/images/frame_0961.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    raise FileNotFoundError(f\"❌ Image '{image_path}' non trouvée. Vérifie le chemin !\")\n",
    "\n",
    "image_height, image_width, _ = image.shape  # Récupérer les dimensions de l'image\n",
    "\n",
    "# Les données en format YOLO (normalisées)\n",
    "yolo_annotations = [\n",
    "    \"0 0.641272 0.528051 0.007079 0.040538\",\n",
    "    \"3 0.580299 0.537974 0.012014 0.032797\",\n",
    "    \"0 0.531456 0.546867 0.019154 0.068575\",\n",
    "    \"0 0.862417 0.542792 0.010402 0.043799\",\n",
    "    \"0 0.881420 0.533255 0.009996 0.037443\",\n",
    "    \"0 0.497308 0.518623 0.004964 0.025324\",\n",
    "    \"2 0.905942 0.531339 0.005652 0.029572\"\n",
    "]\n",
    "\n",
    "# Dessiner les boîtes au format YOLO\n",
    "for annotation in yolo_annotations:\n",
    "    parts = annotation.split()\n",
    "    category_id = int(parts[0])\n",
    "    x_center, y_center, width, height = map(float, parts[1:])\n",
    "\n",
    "    # Convertir les coordonnées normalisées en pixels\n",
    "    x_center_pixel = int(x_center * image_width)\n",
    "    y_center_pixel = int(y_center * image_height)\n",
    "    width_pixel = int(width * image_width)\n",
    "    height_pixel = int(height * image_height)\n",
    "\n",
    "    # Calculer les coordonnées de la boîte : [xmin, ymin, xmax, ymax]\n",
    "    xmin = x_center_pixel - width_pixel // 2\n",
    "    ymin = y_center_pixel - height_pixel // 2\n",
    "    xmax = x_center_pixel + width_pixel // 2\n",
    "    ymax = y_center_pixel + height_pixel // 2\n",
    "\n",
    "    # Dessiner le rectangle\n",
    "    cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "    # Ajouter du texte avec la catégorie\n",
    "    label = f\"Class {category_id}\"\n",
    "    cv2.putText(image, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Afficher l'image avec les boîtes\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convertir BGR -> RGB pour Matplotlib\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Sauvegarder l'image avec les boîtes\n",
    "output_path = \"output_with_yolo_boxes.jpg\"\n",
    "cv2.imwrite(output_path, image)\n",
    "print(f\"✅ Image avec bounding boxes YOLO sauvegardée sous '{output_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2138\n",
      "1050\n",
      "79\n",
      "139\n",
      "3592\n",
      "1054\n",
      "38\n",
      "76\n",
      "3510\n",
      "1067\n",
      "43\n",
      "88\n",
      "2352\n",
      "1067\n",
      "49\n",
      "66\n",
      "2612\n",
      "1040\n",
      "28\n",
      "82\n",
      "3699\n",
      "1057\n",
      "23\n",
      "60\n",
      "2027\n",
      "1037\n",
      "19\n",
      "50\n",
      "914\n",
      "988\n",
      "20\n",
      "49\n",
      "3869\n",
      "1030\n",
      "22\n",
      "46\n",
      "1382\n",
      "1006\n",
      "17\n",
      "36\n",
      "3644\n",
      "1040\n",
      "18\n",
      "45\n",
      "253\n",
      "997\n",
      "17\n",
      "30\n",
      "207\n",
      "996\n",
      "14\n",
      "46\n",
      "190\n",
      "999\n",
      "19\n",
      "46\n",
      "3555\n",
      "1054\n",
      "31\n",
      "76\n",
      "3877\n",
      "1028\n",
      "28\n",
      "48\n",
      "220\n",
      "994\n",
      "19\n",
      "45\n",
      "3543\n",
      "1062\n",
      "24\n",
      "80\n",
      "2567\n",
      "1045\n",
      "11\n",
      "28\n",
      "1591\n",
      "992\n",
      "20\n",
      "41\n",
      "229\n",
      "996\n",
      "16\n",
      "41\n",
      "1636\n",
      "1005\n",
      "16\n",
      "29\n",
      "3818\n",
      "1040\n",
      "19\n",
      "84\n",
      "3667\n",
      "1046\n",
      "11\n",
      "36\n",
      "2541\n",
      "1048\n",
      "10\n",
      "29\n",
      "2592\n",
      "1042\n",
      "14\n",
      "35\n",
      "3402\n",
      "1068\n",
      "27\n",
      "45\n",
      "3735\n",
      "1117\n",
      "20\n",
      "56\n",
      "1884\n",
      "1029\n",
      "24\n",
      "70\n",
      "850\n",
      "997\n",
      "12\n",
      "39\n",
      "725\n",
      "999\n",
      "19\n",
      "48\n",
      "1711\n",
      "1051\n",
      "26\n",
      "39\n",
      "183\n",
      "1011\n",
      "23\n",
      "56\n",
      "2115\n",
      "1049\n",
      "38\n",
      "44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Image avec bounding boxes sauvegardée sous 'frame_0961_labeled.jpg'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 📌 Chemins des fichiers\n",
    "json_file = \"/Users/martin.dejaeghere/Microsint2/runs/detect/val56/predictions.json\"  # Remplace par ton chemin exact\n",
    "image_path = \"/Users/martin.dejaeghere/Microsint2/yolo/datasets_tolabel_copie/one/val/images/frame_0961.jpg\"\n",
    "\n",
    "# 📌 Charger l'image\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    raise ValueError(f\"⚠️ Erreur : Image non trouvée à {image_path}\")\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convertir en RGB pour Matplotlib\n",
    "\n",
    "# 📌 Charger le fichier JSON\n",
    "with open(json_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 📌 Définition des couleurs par catégorie\n",
    "category_colors = {\n",
    "    1: (255, 0, 0),   # Rouge\n",
    "    2: (0, 255, 0),   # Vert\n",
    "    3: (0, 0, 255),   # Bleu\n",
    "    4: (255, 255, 0), # Jaune\n",
    "    5: (255, 0, 255)  # Magenta\n",
    "}\n",
    "\n",
    "# 📌 Tracer les bounding boxes uniquement pour \"frame_0961\"\n",
    "for item in data:\n",
    "    if item[\"image_id\"] == \"frame_0961\":\n",
    "        x, y, w, h = map(int, item[\"bbox\"])\n",
    "        print(x)\n",
    "        print(y)\n",
    "        print(w)\n",
    "        print(h)\n",
    "        category_id = item[\"category_id\"]\n",
    "        score = item.get(\"score\", 0)\n",
    "\n",
    "        # 📌 Sélectionner la couleur selon `category_id`\n",
    "        color = category_colors.get(category_id, (255, 255, 255))  # Blanc par défaut\n",
    "\n",
    "        # 📌 Dessiner le rectangle\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "        # 📌 Ajouter du texte (catégorie + score)\n",
    "        label = f\"Class {category_id} ({score:.2f})\"\n",
    "        cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "# 📌 Afficher l’image\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# 📌 Sauvegarder l’image\n",
    "output_path = \"frame_0961_labeled.jpg\"\n",
    "cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "print(f\"✅ Image avec bounding boxes sauvegardée sous '{output_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hauteur : 2048 pixels\n",
      "Largeur : 4096 pixels\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Vérifier si l'image a été correctement chargée\n",
    "if image is None:\n",
    "    print(f\"❌ Impossible de charger l'image : {image_path}\")\n",
    "else:\n",
    "    # Obtenir la largeur et la hauteur de l'image\n",
    "    height, width = image.shape[:2]\n",
    "    print(f\"Hauteur : {height} pixels\")\n",
    "    print(f\"Largeur : {width} pixels\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
